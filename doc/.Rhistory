# install.packages("tidyr")
library("tidyr")
# install.packages("ggplot2")
library("ggplot2")
# We want to treat each column as characters, not factors, except for the author column.
spooky <- read.csv('../data/spooky.csv', colClasses = 'character')
spooky <- as.tibble(spooky)
spooky$author <- as.factor(spooky$author)
summary(spooky)
# First use tidytext function to drop the punctuations and tokenize our file.
data <- spooky %>%
unnest_tokens(word, text, token = "words", to_lower = TRUE, drop = TRUE)
# Then we get rid of the stop words ("words that are not useful for an analysis, typically extremely common words such as “the”, “of”, “to”, and so forth in English.")
# tidytext has a dictionary for stop words.
data(stop_words)
data <- data %>%
anti_join(stop_words, by = "word")
# frequency <- data %>%
#   count(author, word) %>%
#   group_by(author) %>%
#   mutate(proportion = n / sum(n)) %>%
#   select(-n) %>%
#   spread(author, proportion) %>%
#   gather(author, proportion, c("EAP","MWS"))
#
# ggplot(frequency, aes(x = proportion, y = 'HPL'))
View(data)
?unnest_tokens
# First use tidytext function to drop the punctuations and tokenize our file.
data <- spooky %>%
unnest_tokens(word, text, token = "ngrams", n = 2, to_lower = TRUE, drop = TRUE)
# Then we get rid of the stop words ("words that are not useful for an analysis, typically extremely common words such as “the”, “of”, “to”, and so forth in English.")
# tidytext has a dictionary for stop words.
data(stop_words)
data <- data %>%
anti_join(stop_words, by = "word")
# frequency <- data %>%
#   count(author, word) %>%
#   group_by(author) %>%
#   mutate(proportion = n / sum(n)) %>%
#   select(-n) %>%
#   spread(author, proportion) %>%
#   gather(author, proportion, c("EAP","MWS"))
#
# ggplot(frequency, aes(x = proportion, y = 'HPL'))
View(data)
pronouns <- c("him","she")
?count
data_counts <- data %>%
count(author, word)
View(data_counts)
data_counts <- data %>%
count(word, sort = TRUE)
View(data_counts)
?seperate
?separate
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE)
View(data_counts)
?filter
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter("word1" %in% pronouns)
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns)
View(data_counts)
View(stop_words)
# First use tidytext function to drop the punctuations and tokenize our file.
pronouns <- c("him","she")
data <- spooky %>%
unnest_tokens(word, text, token = "ngrams", n = 2, to_lower = TRUE, drop = TRUE)
# Then we get rid of the stop words ("words that are not useful for an analysis, typically extremely common words such as “the”, “of”, “to”, and so forth in English.")
# tidytext has a dictionary for stop words.
# data(stop_words)
# data <- data %>%
#   anti_join(stop_words, by = "word")
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns) %>%
# frequency <- data %>%
#   count(author, word) %>%
#   group_by(author) %>%
#   mutate(proportion = n / sum(n)) %>%
#   select(-n) %>%
#   spread(author, proportion) %>%
#   gather(author, proportion, c("EAP","MWS"))
#
# ggplot(frequency, aes(x = proportion, y = 'HPL'))
# First use tidytext function to drop the punctuations and tokenize our file.
pronouns <- c("him","she")
data <- spooky %>%
unnest_tokens(word, text, token = "ngrams", n = 2, to_lower = TRUE, drop = TRUE)
# Then we get rid of the stop words ("words that are not useful for an analysis, typically extremely common words such as “the”, “of”, “to”, and so forth in English.")
# tidytext has a dictionary for stop words.
# data(stop_words)
# data <- data %>%
#   anti_join(stop_words, by = "word")
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns)
# frequency <- data %>%
#   count(author, word) %>%
#   group_by(author) %>%
#   mutate(proportion = n / sum(n)) %>%
#   select(-n) %>%
#   spread(author, proportion) %>%
#   gather(author, proportion, c("EAP","MWS"))
#
# ggplot(frequency, aes(x = proportion, y = 'HPL'))
View(data_counts)
?count
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns) %>%
count(word1, word2, wt = n, sort = TRUE)
View(data_counts)
View(data_counts)
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns) %>%
count(word1, word2, wt = n, sort = TRUE) %>%
rename(counts = "nn")
View(data_counts)
data_counts_by_author <- data %>%
count(author, word, sort = TRUE)
View(data_counts_by_author)
data_counts_by_author <- data %>%
count(author, word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE)
View(data_counts_by_author)
data_counts_by_author <- data %>%
count(author, word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns)
View(data_counts_by_author)
View(data_counts_by_author)
View(data_counts)
install.packages("plotly")
library("plotly")
?plot_ly
temp <- plot_ly(data_counts, labels = ~word1, values = ~word2, type = 'pie') %>%
layout(title = 'Pronoun Occurence',
xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
temp
plot_ly(data_counts, labels = ~word1, values = ~word2, type = 'pie') %>%
layout(title = 'Pronoun Occurence',
xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE))
plot_ly(data_counts, labels = ~word1, values = ~word2, type = 'pie') %>%
layout(title = 'Pronoun Occurence')
count(data_counts, word1)
temp <- data.frame(
count(data_counts, word1)
)
View(temp)
View(temp)
ggplot(temp, aes(x="", y=n, fill=word1))+
geom_bar(width = 1, stat = "identity")
ggplot(temp, aes(x="", y=n, fill=word1))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
View(data_counts_by_author)
MWS_po <- data_counts_by_author %>%
filter(author == "MWS")
View(MWS_po)
View(MWS_po)
MWS_po <- data_counts_by_author %>%
filter(author == "MWS") %>%
count(word1)
View(MWS_po)
View(data_counts_by_author)
View(MWS_po)
HPL_po <- data_counts_by_author %>%
filter(author == "HPL") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
MWS_po <- data_counts_by_author %>%
filter(author == "MWS") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
View(MWS_po)
View(data_counts_by_author)
EAP_po <- data_counts_by_author %>%
filter(author == "EAP") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
View(MWS_po)
par(mfrow=c(1,3))
ggplot(MWS_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
ggplot(HPL_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
ggplot(EAP_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
par(mfrow=c(1,3))
ggplot(MWS_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
ggplot(HPL_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
ggplot(EAP_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
# First use tidytext function to drop the punctuations and tokenize our file.
pronouns <- c("him","she")
data <- spooky %>%
unnest_tokens(word, text, token = "ngrams", n = 2, to_lower = TRUE, drop = TRUE)
# Then we get rid of the stop words ("words that are not useful for an analysis, typically extremely common words such as “the”, “of”, “to”, and so forth in English.")
# tidytext has a dictionary for stop words.
# data(stop_words)
# data <- data %>%
#   anti_join(stop_words, by = "word")
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns) %>%
count(word1, word2, wt = n, sort = TRUE) %>%
rename(counts = "nn")
temp <- data.frame(
count(data_counts, word1)
)
ggplot(temp, aes(x="", y=n, fill=word1))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
data_counts_by_author <- data %>%
count(author, word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns)
MWS_po <- data_counts_by_author %>%
filter(author == "MWS") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
HPL_po <- data_counts_by_author %>%
filter(author == "HPL") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
EAP_po <- data_counts_by_author %>%
filter(author == "EAP") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
par(mfrow=c(1,3))
ggplot(MWS_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
ggplot(HPL_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
ggplot(EAP_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
# frequency <- data %>%
#   count(author, word) %>%
#   group_by(author) %>%
#   mutate(proportion = n / sum(n)) %>%
#   select(-n) %>%
#   spread(author, proportion) %>%
#   gather(author, proportion, c("EAP","MWS"))
#
# ggplot(frequency, aes(x = proportion, y = 'HPL'))
p1 <- ggplot(MWS_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
p2 <- ggplot(HPL_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
p3 <- ggplot(EAP_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
par(mfrow=c(1,3))
plot(p1)
plot(p2)
plot(p3)
pie(EAP_po)
?pie
pie(EAP_po$counts,labels = pronoun)
pie(EAP_po$counts,labels = pronouns)
install.packages("pamr")
library("pamr")
pamr.menu(data_counts)
khan.data <- pamr.from.excel("../data/khan.txt", 65, sample.labels=TRUE)
khan.data$x
khan.data$y
?pamr.from.excel
View(data_counts_by_author)
?group_by
word_ratios <- data_counts_by_author %>%
group_by(word2)
View(word_ratios)
word_ratios <- data_counts %>%
group_by(word2)
View(word_ratios)
word_ratios <- data_counts %>%
group_by(word2) %>%
filter(sum(total) > 10)
word_ratios <- data_counts %>%
group_by(word2) %>%
filter(sum(counts) > 10)
View(word_ratios)
word_ratios <- data_counts %>%
group_by(word2) %>%
filter(sum(counts) > 10) %>%
ungroup()
View(word_ratios)
?spread
word_ratios <- data_counts %>%
group_by(word2) %>%
filter(sum(counts) > 10) %>%
ungroup()
View(word_ratios)
word_ratios <- data_counts %>%
group_by(word2) %>%
filter(sum(counts) > 10) %>%
ungroup() %>%
spread(word1, counts, fill = 0)
View(word_ratios)
View(word_ratios)
?mutate_if
View(word_ratios)
word_ratios <- data_counts %>%
group_by(word2) %>%
filter(sum(counts) > 10) %>%
ungroup() %>%
spread(word1, counts, fill = 0) %>%
mutate_if(is.numeric, funs((. + 1) / sum(. + 1)))
View(word_ratios)
funs(. / 3)
temp <- 3
temp %>% funs(./3)
temp %>% mutate_all(funs(./3))
temp <- data.frame("haha"=3)
temp %>% mutate_all(funs(./3))
View(word_ratios)
colSums(word_ratios)
colSums(word_ratios[him])
colSums(word_ratios[,3])
word_ratios <- data_counts %>%
group_by(word2) %>%
filter(sum(counts) > 10) %>%
ungroup() %>%
spread(word1, counts, fill = 0) %>%
mutate_if(is.numeric, funs((. + 1) / sum(. + 1))) %>%
mutate(logratio = log2(she / he)) %>%
arrange(desc(logratio))
View(word_ratios)
pronouns <- c("he","she")
# First use tidytext function to drop the punctuations and tokenize our file.
pronouns <- c("he","she")
data <- spooky %>%
unnest_tokens(word, text, token = "ngrams", n = 2, to_lower = TRUE, drop = TRUE)
# Then we get rid of the stop words ("words that are not useful for an analysis, typically extremely common words such as “the”, “of”, “to”, and so forth in English.")
# tidytext has a dictionary for stop words.
# data(stop_words)
# data <- data %>%
#   anti_join(stop_words, by = "word")
data_counts <- data %>%
count(word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns) %>%
count(word1, word2, wt = n, sort = TRUE) %>%
rename(counts = "nn")
temp <- data.frame(
count(data_counts, word1)
)
ggplot(temp, aes(x="", y=n, fill=word1))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
MWS_po <- data_counts_by_author %>%
filter(author == "MWS") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
HPL_po <- data_counts_by_author %>%
filter(author == "HPL") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
EAP_po <- data_counts_by_author %>%
filter(author == "EAP") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
p1 <- ggplot(MWS_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
p2 <- ggplot(HPL_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
p3 <- ggplot(EAP_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
# frequency <- data %>%
#   count(author, word) %>%
#   group_by(author) %>%
#   mutate(proportion = n / sum(n)) %>%
#   select(-n) %>%
#   spread(author, proportion) %>%
#   gather(author, proportion, c("EAP","MWS"))
#
# ggplot(frequency, aes(x = proportion, y = 'HPL'))
data_counts_by_author <- data %>%
count(author, word, sort = TRUE) %>%
separate(word, c("word1","word2"), sep = " ", remove = TRUE) %>%
filter(word1 %in% pronouns)
word_ratios <- data_counts %>%
group_by(word2) %>%
filter(sum(counts) > 10) %>%
ungroup() %>%
spread(word1, counts, fill = 0) %>%
mutate_if(is.numeric, funs((. + 1) / sum(. + 1))) %>%
mutate(logratio = log2(she / he)) %>%
arrange(desc(logratio))
View(word_ratios)
plot(p1)
View(word_ratios)
View(EAP_po)
View(data_counts)
View(EAP_po)
MWS_po <- data_counts_by_author %>%
filter(author == "MWS") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
View(data_counts_by_author)
View(MWS_po)
HPL_po <- data_counts_by_author %>%
filter(author == "HPL") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
EAP_po <- data_counts_by_author %>%
filter(author == "EAP") %>%
count(word1) %>%
rename(pronoun = "word1", counts = "nn")
p1 <- ggplot(MWS_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
p2 <- ggplot(HPL_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
p3 <- ggplot(EAP_po, aes(x="", y=counts, fill=pronoun))+
geom_bar(width = 1, stat = "identity")+
coord_polar("y", start = 0)
plot(p1)
plot(p2)
plot(p3)
View(word_ratios)
word_ratios %>%
arrange(abs(logratio))
word_ratios %>%
mutate(abslogratio = abs(logratio)) %>%
group_by(logratio < 0)
View(word_ratios)
word_ratios %>%
mutate(abslogratio = abs(logratio)) %>%
group_by(logratio < 0) %>%
top_n(15, abslogratio)
?top_n
?reorder
word_ratios %>%
mutate(abslogratio = abs(logratio)) %>%
group_by(logratio < 0) %>%
top_n(15, abslogratio) %>%
ungroup() %>%
mutate(word = reorder(word2, logratio))
word_ratios %>%
mutate(abslogratio = abs(logratio)) %>%
group_by(logratio < 0) %>%
top_n(15, abslogratio) %>%
ungroup() %>%
mutate(word = reorder(word2, logratio)) %>%
ggplot(aes(word, logratio, color = logratio < 0)) +
geom_segment(aes(x = word, xend = word,
y = 0, yend = logratio),
size = 1.1, alpha = 0.6) +
geom_point(size = 3.5) +
coord_flip() +
labs(x = NULL,
y = "Relative appearance after 'she' compared to 'he'",
title = "Words paired with 'he' and 'she'",
subtitle = "Women remember, read, and feel while men stop, take, and reply") +
scale_color_discrete(name = "", labels = c("More 'she'", "More 'he'")) +
scale_y_continuous(breaks = seq(-3, 3),
labels = c("0.125x", "0.25x", "0.5x",
"Same", "2x", "4x", "8x"))
word_ratios %>%
mutate(abslogratio = abs(logratio)) %>%
group_by(logratio < 0) %>%
top_n(15, abslogratio) %>%
ungroup() %>%
mutate(word = reorder(word2, logratio)) %>%
ggplot(aes(word, logratio, color = logratio < 0)) +
geom_segment(aes(x = word, xend = word,
y = 0, yend = logratio),
size = 1.1, alpha = 0.6) +
geom_point(size = 3.5) +
coord_flip() +
labs(x = NULL,
y = "Relative appearance after 'she' compared to 'he'",
title = "Words paired with 'he' and 'she'",
subtitle = "Women throw, sleep, and turn while men####") +
scale_color_discrete(name = "", labels = c("More 'she'", "More 'he'")) +
scale_y_continuous(breaks = seq(-3, 3),
labels = c("0.125x", "0.25x", "0.5x",
"Same", "2x", "4x", "8x"))
